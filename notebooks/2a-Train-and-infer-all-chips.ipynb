{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we train a random forest model to generate water/not-water inferences on a Planet image. We use the expert-drawn binary classification labels in order to train our models. To train our model -\n",
    "\n",
    "1. For every hand-labeled dataset available, we apply a graph based image segmentation algorithm on a 3 band image containing Green, NDWI and NDVI channels from the source Planet image\n",
    "2. For each segment, we compute pixel value statistics (mean and standard deviation) in the Red, NIR, Green, NDWI and NDVI channels\n",
    "3. These segment statistics are mapped to the corresponding segment labels obtained from the hand-labeled imagery\n",
    "4. We train a random forest model per cropped Planet scene - and then perform inference on the entire available Planet scene\n",
    "\n",
    "At the end of successfully executing the notebook cells, the Planet scene folders will contain a trained random forest model, as well as a file containing model inferences.\n",
    "\n",
    "For example, for the Planet scene `20210903_150800_60_2458` the updated folder structure will be:\n",
    "```\n",
    "    .\n",
    "    ├── data\n",
    "    │   ├─ 20210903_150800_60_2458\n",
    "    │   │  ├─ 20210903_150800_60_2458_3B_AnalyticMS_8b_metadata.xml\n",
    "    │   │  ├─ 20210903_150800_60_2458_3B_AnalyticMS_SR_8b.tif\n",
    "    │   │  ├─ HLS.L30.T18UXG.2021245T154154.v2.0.Fmask.tif\n",
    "    │   │  ├─ OPERA_L3_DSWx-HLS_T18UXG_20210902T154154Z_20230906T035356Z_L8_30_v1.1_B01_WTR.tif\n",
    "    │   │  ├─ OPERA_L3_DSWx-HLS_T18UXG_20210902T154154Z_20230906T035356Z_L8_30_v1.1_B03_CONF.tif\n",
    "    │   │  └─ rf_classification.tif # output inferences\n",
    "    │   ├─ ...    \n",
    "    │   └─ planet_cropped_imagery\n",
    "    │       ├─ 20210903_150800_60_2458\n",
    "    │       │  ├─ rf_model\n",
    "    │       │  │  └─ rf_model.joblib # trained model\n",
    "    │       │  └─ ...      \n",
    "    │       └─ ...\n",
    "    ├── notebooks\n",
    "    │   └─ ...\n",
    "    ├── environment.yml\n",
    "    └── README.md       \n",
    "```\n",
    "Note: Each model is trained on data available for that scene, and may not perform well when applied to other scenes. We will train a single model capable of performing inferences on all the scenes in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIS imports \n",
    "import rasterio\n",
    "\n",
    "# data ETL imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# misc imports\n",
    "from pathlib import Path\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# ML imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from tools import get_superpixel_stds_as_features, get_superpixel_means_as_features, get_array_from_features, reproject_arr_to_match_profile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump\n",
    "\n",
    "# local imports\n",
    "from rf_funcs import calc_ndwi, calc_ndvi, return_grn_indices, return_img_bands, return_reflectance_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data')\n",
    "df = pd.read_csv(data_path/'validation_table.csv')\n",
    "df = df[['site_name', 'planet_id', 'water_stratum']]\n",
    "\n",
    "planet_ids = list(df['planet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Felzenszwalb segmentation parameters\n",
    "F_SCALE = 20 # float value. Larger value returns larger segments\n",
    "F_SIGMA = 0 # float value. Denoising parameter - larger value denoises more and returns smoother segments\n",
    "F_MINSIZE = 20 # int value. Minimum segment size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_trained_rf(chip:str|Path, classification:str|Path, xml_file:str|Path):\n",
    "    \"\"\" \n",
    "    Given a planet image chip and corresponding water/not-water classification mask,\n",
    "    return a trained random forest model. \n",
    "\n",
    "    Save the trained model for future use.\n",
    "    \"\"\"\n",
    "        \n",
    "    band_idxs = return_grn_indices(xml_file)\n",
    "    coeffs = return_reflectance_coeffs(xml_file, band_idxs)\n",
    "    chip_img = return_img_bands(chip, band_idxs, denoising_weight=None)\n",
    "    \n",
    "    with rasterio.open(chip) as src_ds:\n",
    "        ref_profile = src_ds.profile\n",
    "\n",
    "    green = chip_img[0]*coeffs[band_idxs[0]]\n",
    "    red = chip_img[1]*coeffs[band_idxs[1]]\n",
    "    nir = chip_img[2]*coeffs[band_idxs[2]]\n",
    "\n",
    "    with rasterio.open(classification) as src_ds:\n",
    "        cl = src_ds.read(1)\n",
    "        cl_profile = src_ds.profile\n",
    "\n",
    "    # some classification extents are not the same as the corresponding planet chip extent\n",
    "    # if they are not the same, reproject the validation data to match the profile of the planet data\n",
    "    if ((ref_profile['transform'] != cl_profile['transform']) | \n",
    "        (ref_profile['width'] != cl_profile['width']) | \n",
    "        (ref_profile['height'] != cl_profile['height'])):\n",
    "\n",
    "        cl, _ = reproject_arr_to_match_profile(cl, cl_profile, ref_profile)\n",
    "        cl = np.squeeze(cl)\n",
    "\n",
    "    ndwi = calc_ndwi(green, nir)\n",
    "    ndvi = calc_ndvi(red, nir)\n",
    "\n",
    "    # segment image using green, nir, and NDWI channels\n",
    "    img_stack = np.stack([green, nir, ndwi], axis=-1)\n",
    "    segments = felzenszwalb(img_stack, scale=F_SCALE, sigma=F_SIGMA, min_size=F_MINSIZE)\n",
    "\n",
    "    # create training data that includes other channels as well\n",
    "    img_stack = np.stack([red, nir, green, ndwi, ndvi], axis=-1)     \n",
    "    std_features = get_superpixel_stds_as_features(segments, img_stack)\n",
    "    mean_features = get_superpixel_means_as_features(segments, img_stack)\n",
    "\n",
    "    X = np.concatenate([mean_features, std_features], axis = 1)\n",
    "    \n",
    "    # We have superpixels, we now need to map each of the segments to the associated label\n",
    "    # A 0 value indicates no label for the segment\n",
    "    class_features = np.zeros((mean_features.shape[0], 1))\n",
    "    for class_id in [0, 1]:\n",
    "        # Get all superpixel labels with particular id\n",
    "        superpixel_labels_for_class = np.unique(segments[class_id == cl])\n",
    "        # Label those superpixels with approrpriate class\n",
    "        class_features[superpixel_labels_for_class] = class_id\n",
    "\n",
    "    # Define an RF to be trained. setting n_jobs = -1 uses all available processors\n",
    "    rf = RandomForestClassifier(n_estimators=250, class_weight='balanced', oob_score=True, random_state=0, n_jobs=-1)\n",
    "\n",
    "    # train model on all of the available data\n",
    "    rf.fit(X, class_features.ravel())\n",
    "\n",
    "    rf_model_folder = Path(chip).parent / 'rf_model'\n",
    "    rf_model_folder.mkdir(exist_ok=True)\n",
    "    model_path = rf_model_folder/\"rf_model.joblib\"\n",
    "    \n",
    "    # save for later use\n",
    "    dump(rf, model_path)\n",
    "\n",
    "    return rf\n",
    "\n",
    "def generate_inference(rf, img:str|Path, xml_file:str|Path):\n",
    "    band_idxs = return_grn_indices(xml_file)\n",
    "    coeffs = return_reflectance_coeffs(xml_file, band_idxs)\n",
    "    \n",
    "    full_img = return_img_bands(img, band_idxs, denoising_weight=None)\n",
    "\n",
    "    green = full_img[0]*coeffs[band_idxs[0]]\n",
    "    red = full_img[1]*coeffs[band_idxs[1]]\n",
    "    nir = full_img[2]*coeffs[band_idxs[2]]\n",
    "\n",
    "    ndwi = calc_ndwi(green, nir)\n",
    "    ndvi = calc_ndvi(red, nir)\n",
    "\n",
    "    img_stack = np.stack([green, nir, ndwi], axis=-1)\n",
    "    segments = felzenszwalb(img_stack, scale=F_SCALE, sigma=F_SIGMA, min_size=F_MINSIZE)\n",
    "\n",
    "    # for inference we include other channels as well\n",
    "    img_stack = np.stack([red, nir, green, ndwi, ndvi], axis=-1)\n",
    "    std_features = get_superpixel_stds_as_features(segments, img_stack)\n",
    "    mean_features = get_superpixel_means_as_features(segments, img_stack)\n",
    "\n",
    "    X = np.concatenate([mean_features, std_features], axis = 1)\n",
    "    y = rf.predict(X)\n",
    "\n",
    "    return get_array_from_features(segments, np.expand_dims(y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_infer(planet_id):\n",
    "    \"\"\" \n",
    "    This function takes in a planet_id and finds the appropriate cropped planet image and corresponding hand labeled data\n",
    "    We use this data to train a random forest model, and subsequently use the model to perform inference on the larger \n",
    "    Planet image. \n",
    "    \n",
    "    We write out the inferences to a new file.\n",
    "    \"\"\"\n",
    "    data_path = Path('../data')\n",
    "    \n",
    "    current_img_path = data_path / planet_id\n",
    "    cropped_img_path = data_path / 'planet_images_cropped' / planet_id\n",
    "    xml_file = list(current_img_path.glob('*.xml'))[0]\n",
    "\n",
    "    img = list(current_img_path.glob(f'{planet_id}*.tif'))[0]\n",
    "    chip = list(cropped_img_path.glob(f'cropped_{planet_id}*.tif'))[0]\n",
    "    classification = list(cropped_img_path.glob(f'classification_*.tif'))[0]\n",
    "\n",
    "    rf = return_trained_rf(chip=chip, classification=classification, xml_file=xml_file)\n",
    "    inference = generate_inference(rf, img, xml_file)\n",
    "\n",
    "    # use planet image to mask out regions of no data in the model inference\n",
    "    with rasterio.open(img) as src_ds:\n",
    "        nodata_mask = np.where(src_ds.read(1) == src_ds.profile['nodata'], 1, 0)\n",
    "        inference[nodata_mask==1] = 255\n",
    "        profile_copy = src_ds.profile\n",
    "        profile_copy.update({'count':1, 'dtype':np.uint8, 'nodata':255})\n",
    "\n",
    "        # write out model inference\n",
    "        with rasterio.open(f\"{img.parent}/rf_classification.tif\", 'w', **profile_copy) as dst_ds:\n",
    "            dst_ds.write(inference.astype(np.uint8).reshape(1, *inference.shape))\n",
    "\n",
    "    print(f\"Completed inference for planet id {planet_id}\")\n",
    "    \n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on one site\n",
    "model_features = [\"red_mean\", \"nir_mean\", \"green_mean\", \"ndwi_mean\", \"ndvi_mean\", \"red_std\", \"nir_std\", \"green_std\", \"ndwi_std\", \"ndvi_std\"]\n",
    "model = train_and_infer(planet_ids[0])\n",
    "feature_importances = list(zip(model_features, model.feature_importances_)) \n",
    "\n",
    "# The feature importances sum to 1, and provide an idea of how the model weights\n",
    "# various features in making water/not-water inferences\n",
    "print(f\"Feature importances: {feature_importances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inferences on remaining sites\n",
    "# We use multiprocessing to speed things up - \n",
    "# change the value of N_PROC below to use more/fewer parallel processes\n",
    "\n",
    "N_PROC = 4\n",
    "PARALLEL_EXECUTION = False\n",
    "\n",
    "if PARALLEL_EXECUTION:\n",
    "    with Pool(N_PROC) as p:\n",
    "        for id in planet_ids[1:]:\n",
    "            _ = p.apply_async(train_and_infer, (id,))\n",
    "\n",
    "        p.close()\n",
    "        p.join()\n",
    "else:\n",
    "    _ = list(map(generate_inference, planet_ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
