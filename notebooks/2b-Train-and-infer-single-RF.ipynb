{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In training RFs to expand our validation dataset, we've come across two situations that are not captured by the approach thus far - \n",
    "1. The spectral characteristics of water within the validation chip is not representative of water surfaces present in the broader Planet image\n",
    "2. A validation chip contains no water classification, while the broader Planet image contains some water. Since the RF trained on this data is not given any OSW examples, it will classify the entire Planet image as \"not-water\"\n",
    "\n",
    "We can mitigate this by training a single model on validation data from multiple sites, rather than on a per-site basis.\n",
    "\n",
    "This notebook demonstrates how to train a random forest model using all of the available validation data, and produce water/not-water inferences.\n",
    "\n",
    "At the end of successfully executing the notebook cells, the `data` folder will contain a trained random forest model within the `trained_models/rf_model` folder , and each of the Planet scene folders will contain a file with model inferences.\n",
    "\n",
    "For example, for the Planet scene `20210903_150800_60_2458` the updated folder structure will be:\n",
    "```\n",
    "    .\n",
    "    ├── data\n",
    "    │   ├─ 20210903_150800_60_2458\n",
    "    │   │  ├─ 20210903_150800_60_2458_3B_AnalyticMS_8b_metadata.xml\n",
    "    │   │  ├─ 20210903_150800_60_2458_3B_AnalyticMS_SR_8b.tif\n",
    "    │   │  ├─ HLS.L30.T18UXG.2021245T154154.v2.0.Fmask.tif\n",
    "    │   │  ├─ OPERA_L3_DSWx-HLS_T18UXG_20210902T154154Z_20230906T035356Z_L8_30_v1.1_B01_WTR.tif\n",
    "    │   │  ├─ OPERA_L3_DSWx-HLS_T18UXG_20210902T154154Z_20230906T035356Z_L8_30_v1.1_B03_CONF.tif\n",
    "    │   │  ├─ rf_classification.tif\n",
    "    │   │  └─ new_rf_classification.tif # output inferences\n",
    "    │   ├─ ...    \n",
    "    │   └─ trained_models\n",
    "    │      └─ rf_model\n",
    "    │         └─ rf_model.joblib # trained model\n",
    "    ├── notebooks\n",
    "    │   └─ ...\n",
    "    ├── environment.yml\n",
    "    └── README.md       \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIS/data imports\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML imports\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from tools import get_superpixel_stds_as_features, get_superpixel_means_as_features, get_array_from_features, reproject_arr_to_match_profile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from joblib import dump\n",
    "\n",
    "# misc imports\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from typing import Union\n",
    "\n",
    "# local imports\n",
    "from rf_funcs import calc_ndwi, calc_ndvi, return_grn_indices, return_img_bands, return_reflectance_coeffs\n",
    "\n",
    "# for repeatability\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to false if only performing inference with a previously trained model\n",
    "RETRAIN_MODEL= True\n",
    "\n",
    "# Set to false to skip inference step\n",
    "MAKE_INFERENCES = True \n",
    "\n",
    "EVALUATE_MODEL = True # Split available data and print model performance on test set\n",
    "TEST_SET_SPLIT = 0.15 # If evaluating model, specify data split for testing. train split will be 1-TEST_SET_SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Felzenszwalb segmentation parameters\n",
    "F_SCALE = 20 # float value. Larger value returns larger segments\n",
    "F_SIGMA = 0 # float value. Denoising parameter - larger value denoises more and returns smoother segments\n",
    "F_MINSIZE = 20 # int value. Minimum segment size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation database\n",
    "data_path = Path('../data/')\n",
    "val_chips_db = data_path / 'validation_table.csv'\n",
    "val_df = pd.read_csv(val_chips_db)\n",
    "\n",
    "site_names = list(val_df['site_name'])\n",
    "planet_ids = list(val_df['planet_id'])\n",
    "\n",
    "# Extract planet IDs and associated strata\n",
    "site_names_stratified = defaultdict(list)\n",
    "for sn, planet_id in zip(site_names, planet_ids):\n",
    "    site_names_stratified[sn[:2]].append(planet_id)\n",
    "\n",
    "training_sites = []\n",
    "\n",
    "# We can modify strata_list to exclude certain scenes from the training data\n",
    "strata_list = ['1_', '2_', '3_', '4_']\n",
    "\n",
    "for key in site_names_stratified.keys():\n",
    "    if key in strata_list:\n",
    "        training_sites.extend(site_names_stratified[key])\n",
    "\n",
    "print(\"# of Training sites: \", len(training_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation database\n",
    "data_path = Path('../data/')\n",
    "val_chips_db = data_path / 'validation_table.csv'\n",
    "val_df = pd.read_csv(val_chips_db)\n",
    "\n",
    "site_names = list(val_df['site_name'])\n",
    "planet_ids = list(val_df['planet_id'])\n",
    "\n",
    "# Extract planet IDs and associated strata\n",
    "site_names_stratified = defaultdict(list)\n",
    "for sn, planet_id in zip(site_names, planet_ids):\n",
    "    site_names_stratified[sn[:2]].append(planet_id)\n",
    "\n",
    "print(site_names_stratified.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the name of the planet ids. For each, do the following - \n",
    "1. Read the cropped planet image and the corresponding validation labels\n",
    "2. Generate superpixels and calculate mean and std dev.\n",
    "3. Append to list\n",
    "4. Train and save model\n",
    "5. Apply model to broader Planet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_folder = data_path / 'trained_models' / 'rf_model'\n",
    "rf_model_folder.mkdir(exist_ok=True, parents=True)\n",
    "model_path = rf_model_folder/\"rf_model_alldata.joblib\"\n",
    "\n",
    "if RETRAIN_MODEL:\n",
    "    with open(f\"{model_path}.txt\", 'w') as f:\n",
    "        f.write(f\"FELZENSZWALB SCALE:{F_SCALE}\\n\")\n",
    "        f.write(f\"FELZENSZWALB MIN SIZE:{F_MINSIZE}\\n\")\n",
    "        f.write(f\"FELZENSZWALB SIGMA:{F_SIGMA}\\n\")\n",
    "        \n",
    "    X, class_features = None, None\n",
    "    for idx, site in enumerate(training_sites):\n",
    "        print(f\"Currently processing site # {idx}\")\n",
    "\n",
    "        current_img_path = data_path / site\n",
    "        cropped_img_path = data_path / 'planet_images_cropped' / site\n",
    "        \n",
    "        xml_file = list(current_img_path.glob('*.xml'))[0]\n",
    "        chip = list(cropped_img_path.glob(f'cropped_{site}*.tif'))[0]\n",
    "        classification = list(cropped_img_path.glob(f'site_name*{site}*.tif'))[0]\n",
    "\n",
    "        band_idxs = return_grn_indices(xml_file)\n",
    "        coeffs = return_reflectance_coeffs(xml_file, band_idxs)\n",
    "        chip_img = return_img_bands(chip, band_idxs, denoising_weight=None)\n",
    "\n",
    "        with rasterio.open(chip) as src_ds:\n",
    "            ref_profile = src_ds.profile\n",
    "\n",
    "        green = chip_img[0]*coeffs[band_idxs[0]]\n",
    "        red = chip_img[1]*coeffs[band_idxs[1]]\n",
    "        nir = chip_img[2]*coeffs[band_idxs[2]]\n",
    "\n",
    "        with rasterio.open(classification) as src_ds:\n",
    "            cl = src_ds.read(1)\n",
    "            cl_profile = src_ds.profile\n",
    "\n",
    "        # some classification extents are not the same as the corresponding planet chip extent\n",
    "        # if they are not the same, reproject the validation data to match the profile of the planet data\n",
    "        if ((ref_profile['transform'] != cl_profile['transform']) | \n",
    "            (ref_profile['width'] != cl_profile['width']) | \n",
    "            (ref_profile['height'] != cl_profile['height'])):\n",
    "\n",
    "            cl, _ = reproject_arr_to_match_profile(cl, cl_profile, ref_profile)\n",
    "            cl = np.squeeze(cl)\n",
    "\n",
    "        ndwi = calc_ndwi(green, nir)\n",
    "        ndvi = calc_ndvi(red, nir)\n",
    "\n",
    "        # segment image using green, nir, and NDWI channels\n",
    "        img_stack = np.stack([green, nir, ndwi], axis=-1)\n",
    "        segments = felzenszwalb(img_stack, scale=F_SCALE, sigma=F_SIGMA, min_size=F_MINSIZE)\n",
    "\n",
    "        # create training data that includes other channels as well\n",
    "        img_stack = np.stack([red, nir, green, ndwi, ndvi], axis=-1)     \n",
    "        std_features = get_superpixel_stds_as_features(segments, img_stack)\n",
    "        mean_features = get_superpixel_means_as_features(segments, img_stack)\n",
    "\n",
    "        if X is None:\n",
    "            X = np.concatenate([mean_features, std_features], axis = 1)\n",
    "        else:\n",
    "            X_temp = np.concatenate([mean_features, std_features], axis = 1)\n",
    "            X = np.concatenate([X, X_temp], axis=0)\n",
    "\n",
    "        # We have superpixels, we now need to map each of the segments to the associated label\n",
    "        # A 0 value indicates no label for the segment\n",
    "        \n",
    "        class_features_temp = np.zeros((mean_features.shape[0], 1)) + 255\n",
    "        for class_id in [0, 1]:\n",
    "            # Get all superpixel labels with particular id\n",
    "            superpixel_labels_for_class = np.unique(segments[class_id == cl])\n",
    "            # Label those superpixels with approrpriate class\n",
    "            class_features_temp[superpixel_labels_for_class] = class_id\n",
    "\n",
    "        if class_features is None:\n",
    "            class_features = class_features_temp\n",
    "        else:\n",
    "            class_features = np.concatenate([class_features, class_features_temp], axis=0)\n",
    "\n",
    "\n",
    "    print(\"Beginning model training\")\n",
    "    # Define an RF to be trained. setting n_jobs = -1 uses all available processors\n",
    "    rf = RandomForestClassifier(n_estimators=300, class_weight='balanced', oob_score=True, random_state=0, n_jobs=-1)\n",
    "\n",
    "    # train model on all of the available data\n",
    "    rf.fit(X, class_features.ravel())\n",
    "\n",
    "    # save for later use\n",
    "    dump(rf, model_path)\n",
    "\n",
    "else: # If a trained model already exists, load weights\n",
    "    rf = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make inferences on the broader planet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inference_helper(rf, img:str|Path, xml_file:str|Path):\n",
    "    band_idxs = return_grn_indices(xml_file)\n",
    "    coeffs = return_reflectance_coeffs(xml_file, band_idxs)\n",
    "    \n",
    "    full_img = return_img_bands(img, band_idxs, denoising_weight=None)\n",
    "\n",
    "    green = full_img[0]*coeffs[band_idxs[0]]\n",
    "    red = full_img[1]*coeffs[band_idxs[1]]\n",
    "    nir = full_img[2]*coeffs[band_idxs[2]]\n",
    "\n",
    "    ndwi = calc_ndwi(green, nir)\n",
    "    ndvi = calc_ndvi(red, nir)\n",
    "\n",
    "    img_stack = np.stack([green, nir, ndwi], axis=-1)\n",
    "    segments = felzenszwalb(img_stack, scale=F_SCALE, sigma=F_SIGMA, min_size=F_MINSIZE)\n",
    "\n",
    "    # for inference we include other channels as well\n",
    "    img_stack = np.stack([red, nir, green, ndwi, ndvi], axis=-1)\n",
    "    std_features = get_superpixel_stds_as_features(segments, img_stack)\n",
    "    mean_features = get_superpixel_means_as_features(segments, img_stack)\n",
    "\n",
    "    X = np.concatenate([mean_features, std_features], axis = 1)\n",
    "    y = rf.predict(X)\n",
    "\n",
    "    return get_array_from_features(segments, np.expand_dims(y, axis=1))\n",
    "\n",
    "def generate_inference(planet_id):\n",
    "    \"\"\" \n",
    "    This function takes in a planet_id and generates inferences for the overlapping planet image\n",
    "    \"\"\"\n",
    "    data_path = Path('../data')\n",
    "    \n",
    "    current_img_path = data_path / planet_id\n",
    "    cropped_img_path = data_path / 'planet_images_cropped' / planet_id\n",
    "    xml_file = list(current_img_path.glob('*.xml'))[0]\n",
    "    classification = list(cropped_img_path.glob(f'classification_*.tif'))[0]\n",
    "\n",
    "    img = list(current_img_path.glob(f'{planet_id}*.tif'))[0]\n",
    "\n",
    "    inference = generate_inference_helper(rf, img, xml_file)\n",
    "\n",
    "    # use planet image to mask out regions of no data in the model inference\n",
    "    with rasterio.open(img) as src_ds:\n",
    "        nodata_mask = np.where(src_ds.read(1) == src_ds.profile['nodata'], 1, 0)\n",
    "        inference[nodata_mask==1] = 255\n",
    "        profile_copy = src_ds.profile\n",
    "        profile_copy.update({'count':1, 'dtype':np.uint8, 'nodata':255})\n",
    "\n",
    "        # write out model inference\n",
    "        with rasterio.open(f\"{classification.parent}/new_rf_classification.tif\", 'w', **profile_copy) as dst_ds:\n",
    "            dst_ds.write(inference.astype(np.uint8).reshape(1, *inference.shape))\n",
    "\n",
    "    print(f\"Completed inference for plane id {planet_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = [\"red_mean\", \"nir_mean\", \"green_mean\", \"ndwi_mean\", \"ndvi_mean\", \"red_std\", \"nir_std\", \"green_std\", \"ndwi_std\", \"ndvi_std\"]\n",
    "feature_importances = list(zip(model_features, rf.feature_importances_))\n",
    "print(f\"Feature importances: {feature_importances}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = list(map(generate_inference, planet_id[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After successfully completing one inference, do the rest of the scenes\n",
    "_ = list(map(generate_inference, tqdm(planet_ids[1:])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 64-bit ('expand-validation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d7560f7704abad77a83f3584272055367e63478e3eef1282c4e194da960c77d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
