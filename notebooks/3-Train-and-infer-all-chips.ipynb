{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIS imports \n",
    "import rasterio\n",
    "\n",
    "# data ETL imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# misc imports\n",
    "from pathlib import Path\n",
    "from xml.dom import minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# ML imports\n",
    "from skimage.restoration import denoise_tv_bregman\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skimage.segmentation import felzenszwalb\n",
    "from tools import get_superpixel_stds_as_features, get_superpixel_means_as_features, get_array_from_features, reproject_arr_to_match_profile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>planet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210916_010848_94_2407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 planet_id\n",
       "0  20210916_010848_94_2407"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path/'validation_table.csv')\n",
    "df = df[['site_name', 'planet_id', 'water_stratum']]\n",
    "\n",
    "# notebook disconnected and stopped working. delete ONLY this line after all inferences are generated\n",
    "df = pd.DataFrame({'planet_id':[f.name for f in (data_path/'planet_images_cropped').iterdir() if len(list(f.glob('full_img_rf*'))) == 0]})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to read Planet imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_grn_indices(xml_file:str|Path)->list:\n",
    "    \"\"\" \n",
    "    Return the indices of the (green, red, and NIR) channels of a 4 or 8 band Planet image\n",
    "    \"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    numbands = None\n",
    "    for elem in tree.iter():\n",
    "        if 'numBands' in elem.tag:\n",
    "            numBands = int(elem.text)\n",
    "        \n",
    "    # print(f\"Chip id: {row.planet_id}, bands: {numBands}\")\n",
    "\n",
    "    # we always want (green, red, nir) indices in the image\n",
    "    if numBands == 4:\n",
    "        band_idxs = [2, 3, 4] # BGRN image\n",
    "    else:\n",
    "        band_idxs = [4, 6, 8] # 8 band MS image\n",
    "    \n",
    "    return band_idxs\n",
    "\n",
    "def return_reflectance_coeffs(xml_file:str|Path, band_idx:int|list):\n",
    "    \"\"\"\n",
    "    Read XML file associated with a Planet image and return the TOA reflectance coefficients\n",
    "    for specified band indices\n",
    "    \"\"\"\n",
    "    assert isinstance(band_idx, (list, int)), \"band_idx must be of type int or list\"\n",
    "    \n",
    "    if isinstance(band_idx, int):\n",
    "        band_idx = [band_idx]\n",
    "    \n",
    "    # parse XML metadata to obtain TOA reflectance coefficients\n",
    "    xmldoc = minidom.parse(str(xml_file))\n",
    "    nodes = xmldoc.getElementsByTagName(\"ps:bandSpecificMetadata\")\n",
    "    coeffs = {}\n",
    "    for node in nodes:\n",
    "        bn = node.getElementsByTagName(\"ps:bandNumber\")[0].firstChild.data\n",
    "        if bn in [str(x) for x in band_idx]:\n",
    "            i = int(bn)\n",
    "            value = node.getElementsByTagName(\"ps:reflectanceCoefficient\")[0].firstChild.data\n",
    "            coeffs[i] = float(value)\n",
    "    \n",
    "    return coeffs\n",
    "\n",
    "def return_img_bands(img:str|Path, band_idx:int|list, denoising_weight=None)->np.ndarray:\n",
    "    \"\"\" \n",
    "    Read a Planet file and return an numpy array containing data from specified bands. The image \n",
    "    will be band-wise denoised (using TV denoising) if a denoising weight is specified\n",
    "    \"\"\"\n",
    "    if isinstance(band_idx, int):\n",
    "        band_idx = list(band_idx)\n",
    "    \n",
    "    img_stack = []\n",
    "    with rasterio.open(img) as ds:\n",
    "        for idx in band_idx:\n",
    "            if denoising_weight is not None:\n",
    "                img_stack.append(denoise_tv_bregman(ds.read(idx), denoising_weight))\n",
    "            else:\n",
    "                img_stack.append(ds.read(idx))\n",
    "    \n",
    "    return np.stack(img_stack, axis = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to train a random forest and produce inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ndwi(green, red, min_value=1e-5):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ndwi = (green - red)/(green + red)\n",
    "    ndwi = np.where(np.isnan(ndwi), min_value, ndwi)\n",
    "    return ndwi\n",
    "\n",
    "def calc_ndvi(red, nir, min_value=1e-5):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ndvi = (red - nir)/(red + nir)\n",
    "    ndvi = np.where(np.isnan(ndvi), min_value, ndvi)\n",
    "    return ndvi\n",
    "\n",
    "def return_trained_rf(chip:str|Path, classification:str|Path, xml_file:str|Path):\n",
    "        \n",
    "    band_idxs = return_grn_indices(xml_file)\n",
    "    coeffs = return_reflectance_coeffs(xml_file, band_idxs)\n",
    "    chip_img = return_img_bands(chip, band_idxs, denoising_weight=None)\n",
    "    \n",
    "    with rasterio.open(chip) as src_ds:\n",
    "        ref_profile = src_ds.profile\n",
    "\n",
    "    green = chip_img[0]*coeffs[band_idxs[0]]\n",
    "    red = chip_img[1]*coeffs[band_idxs[1]]\n",
    "    nir = chip_img[2]*coeffs[band_idxs[2]]\n",
    "\n",
    "    with rasterio.open(classification) as src_ds:\n",
    "        cl = src_ds.read(1)\n",
    "        cl_profile = src_ds.profile\n",
    "\n",
    "    # some classification extents are not the same as the corresponding chip extent\n",
    "    # this will be reflected in the transforms of the two rasters\n",
    "    # if this is the case, reproject the classification such that it matches the chip extent\n",
    "    if ref_profile['transform'] != cl_profile['transform']:\n",
    "        ref_transform = ref_profile['transform']\n",
    "        width = ref_profile['width']\n",
    "        height = ref_profile['height']\n",
    "        ref_profile = cl_profile.copy()\n",
    "        ref_profile.update({'transform':ref_transform, 'width':width, 'height': height})\n",
    "        cl, _ = reproject_arr_to_match_profile(cl, cl_profile, ref_profile)\n",
    "        cl = np.squeeze(cl)\n",
    "\n",
    "    ndwi_1 = calc_ndwi(green, red)\n",
    "    ndwi_2 = calc_ndwi(green, nir)\n",
    "    ndvi = calc_ndvi(red, nir)\n",
    "\n",
    "    # segment image using red and NDWI channels\n",
    "    img_stack = np.stack([red, ndwi_1, ndwi_2], axis=-1)\n",
    "    segments = felzenszwalb(img_stack, sigma=0, min_size=3)\n",
    "\n",
    "    # create training data that includes other channels as well\n",
    "    img_stack = np.stack([red, nir, green, ndwi_1, ndwi_2, ndvi], axis=-1)    \n",
    "    std_features = get_superpixel_stds_as_features(segments, img_stack)\n",
    "    mean_features = get_superpixel_means_as_features(segments, img_stack)\n",
    "\n",
    "    X = np.concatenate([mean_features, std_features], axis = 1)\n",
    "    \n",
    "    # We have superpixels, we now need to map each of the segments to the associated label\n",
    "    # A 0 value indicates no label for the segment\n",
    "    class_features = np.zeros((mean_features.shape[0], 1))\n",
    "    for class_id in [0, 1]:\n",
    "        # Get all superpixel labels with particular id\n",
    "        superpixel_labels_for_class = np.unique(segments[class_id == cl])\n",
    "        # Label those superpixels with approrpriate class\n",
    "        class_features[superpixel_labels_for_class] = class_id\n",
    "\n",
    "    class_arr_superpixels = get_array_from_features(segments, class_features)\n",
    "\n",
    "    # Split data into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, class_features, test_size=0.15, random_state=0)\n",
    "\n",
    "    # Define an RF to be trained. setting n_jobs = -1 uses all available processors\n",
    "    rf = RandomForestClassifier(n_estimators=250, class_weight='balanced', oob_score=True, random_state=0, n_jobs=-1)\n",
    "\n",
    "    # # train model and print performance\n",
    "    rf.fit(X_train, y_train.ravel())\n",
    "    # print(\"Model OOB score: \", rf.oob_score_)\n",
    "    # print(\"Model test score: \", rf.score(X_test, y_test.ravel()))\n",
    "\n",
    "    rf_model_folder = Path(chip).parent / 'rf_model'\n",
    "    rf_model_folder.mkdir(exist_ok=True)\n",
    "    model_path = rf_model_folder/\"rf_model.joblib\"\n",
    "    \n",
    "    # save for later use\n",
    "    dump(rf, model_path)\n",
    "\n",
    "    return rf\n",
    "\n",
    "def generate_inference(rf, img:str|Path, xml_file:str|Path):\n",
    "    band_idxs = return_grn_indices(xml_file)\n",
    "    coeffs = return_reflectance_coeffs(xml_file, band_idxs)\n",
    "    \n",
    "    full_img = return_img_bands(img, band_idxs, denoising_weight=None)\n",
    "\n",
    "    green = full_img[0]*coeffs[band_idxs[0]]\n",
    "    red = full_img[1]*coeffs[band_idxs[1]]\n",
    "    nir = full_img[2]*coeffs[band_idxs[2]]\n",
    "\n",
    "    ndwi_1 = calc_ndwi(green, red)\n",
    "    ndwi_2 = calc_ndwi(green, nir)\n",
    "    ndvi = calc_ndvi(red, nir)\n",
    "\n",
    "    img_stack = np.stack([red, ndwi_1, ndwi_2], axis=-1)\n",
    "    segments = felzenszwalb(img_stack, sigma=0, min_size=3)\n",
    "\n",
    "    # for inference we include other channels as well\n",
    "    img_stack = np.stack([red, nir, green, ndwi_1, ndwi_2, ndvi], axis=-1) \n",
    "    std_features = get_superpixel_stds_as_features(segments, img_stack)\n",
    "    mean_features = get_superpixel_means_as_features(segments, img_stack)\n",
    "\n",
    "    X = np.concatenate([mean_features, std_features], axis = 1)\n",
    "    y = rf.predict(X)\n",
    "\n",
    "    return get_array_from_features(segments, np.expand_dims(y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_infer(row):\n",
    "    data_path = Path('../data')\n",
    "    \n",
    "    current_img_path = data_path / row.planet_id\n",
    "    cropped_img_path = data_path / 'planet_images_cropped' / row.planet_id\n",
    "    xml_file = list(current_img_path.glob('*.xml'))[0]\n",
    "\n",
    "    img = list(current_img_path.glob(f'{row.planet_id}*.tif'))[0]\n",
    "    chip = list(cropped_img_path.glob(f'cropped_{row.planet_id}*.tif'))[0]\n",
    "    classification = list(cropped_img_path.glob(f'*{row.planet_id}*.tif'))[0]\n",
    "\n",
    "    rf = return_trained_rf(chip=chip, classification=classification, xml_file=xml_file)\n",
    "    inference = generate_inference(rf, img, xml_file)\n",
    "\n",
    "    with rasterio.open(img) as src_ds:\n",
    "        profile_copy = src_ds.profile\n",
    "        profile_copy.update({'count':1, 'dtype':np.uint8, 'nodata':255})\n",
    "        with rasterio.open(f\"{classification.parent}/full_img_rf_classification_{classification.name}\", 'w', **profile_copy) as dst_ds:\n",
    "            dst_ds.write(inference.astype(np.uint8).reshape(1, *inference.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:640: RuntimeWarning: invalid value encountered in divide\n",
      "  means = sums / counts\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:640: RuntimeWarning: invalid value encountered in divide\n",
      "  means = sums / counts\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:640: RuntimeWarning: invalid value encountered in divide\n",
      "  means = sums / counts\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:640: RuntimeWarning: invalid value encountered in divide\n",
      "  means = sums / counts\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:640: RuntimeWarning: invalid value encountered in divide\n",
      "  means = sums / counts\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/sklearn/ensemble/_base.py:229: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:640: RuntimeWarning: invalid value encountered in divide\n",
      "  means = sums / counts\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:640: RuntimeWarning: invalid value encountered in divide\n",
      "  means = sums / counts\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:640: RuntimeWarning: invalid value encountered in divide\n",
      "  means = sums / counts\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/sklearn/ensemble/_base.py:229: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:640: RuntimeWarning: invalid value encountered in divide\n",
      "  means = sums / counts\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:640: RuntimeWarning: invalid value encountered in divide\n",
      "  means = sums / counts\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/scipy/ndimage/_measurements.py:640: RuntimeWarning: invalid value encountered in divide\n",
      "  means = sums / counts\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/sklearn/ensemble/_base.py:229: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/sklearn/ensemble/_base.py:229: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/sklearn/ensemble/_base.py:229: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.15 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_25308/950550237.py\", line 12, in train_and_infer\n    rf = return_trained_rf(chip=chip, classification=classification, xml_file=xml_file)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_25308/4077836579.py\", line 69, in return_trained_rf\n    X_train, X_test, y_train, y_test = train_test_split(X, class_features, test_size=0.15, random_state=0)\n                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/sklearn/model_selection/_split.py\", line 2562, in train_test_split\n    n_train, n_test = _validate_shuffle_split(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/site-packages/sklearn/model_selection/_split.py\", line 2236, in _validate_shuffle_split\n    raise ValueError(\nValueError: With n_samples=1, test_size=0.15 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m----> 2\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_and_infer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m/u/trappist-r0/karthikv/mambaforge/envs/expand-validation/lib/python3.11/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=1, test_size=0.15 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "with Pool(4) as pool:\n",
    "    _ = pool.map(train_and_infer, [row for _, row in df.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('expand-validation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a751338cf89ec1649cdf743d3dc7fe23ec82d22a9f9be14ff02c9be8441ee2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
